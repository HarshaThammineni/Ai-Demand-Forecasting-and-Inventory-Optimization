{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Demand Forecasting and Inventory Optimization\n",
    "### Interactive Notebook for Learning and Experimentation\n",
    "\n",
    "This notebook provides an interactive way to explore demand forecasting and inventory optimization.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand time series forecasting\n",
    "- Compare multiple ML models\n",
    "- Learn inventory optimization concepts\n",
    "- Visualize business insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 2: Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('retail_sales_data.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"\\nProducts: {df['product'].unique()}\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by product\n",
    "print(\"Demand Statistics by Product:\")\n",
    "df.groupby('product')['demand'].agg(['mean', 'std', 'min', 'max', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize demand over time for all products\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, product in enumerate(df['product'].unique()):\n",
    "    product_data = df[df['product'] == product]\n",
    "    axes[idx].plot(product_data['date'], product_data['demand'], alpha=0.7)\n",
    "    axes[idx].set_title(f'{product} - Demand Over Time')\n",
    "    axes[idx].set_xlabel('Date')\n",
    "    axes[idx].set_ylabel('Demand')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[-1].axis('off')  # Hide the last subplot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze patterns\n",
    "print(\"üìä Demand Patterns Analysis\\n\")\n",
    "\n",
    "# Weekend vs Weekday\n",
    "print(\"Weekend vs Weekday Demand:\")\n",
    "print(df.groupby('is_weekend')['demand'].mean())\n",
    "\n",
    "print(\"\\nPromotion Impact:\")\n",
    "print(df.groupby('is_promotion')['demand'].mean())\n",
    "\n",
    "print(\"\\nMonthly Demand Pattern:\")\n",
    "print(df.groupby('month')['demand'].mean().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Step 4: Feature Engineering\n",
    "\n",
    "Create lag features and rolling statistics for better forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, product_name):\n",
    "    \"\"\"Create time series features\"\"\"\n",
    "    product_df = df[df['product'] == product_name].copy()\n",
    "    product_df = product_df.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    # Lag features\n",
    "    for lag in [1, 7, 14, 30]:\n",
    "        product_df[f'lag_{lag}'] = product_df['demand'].shift(lag)\n",
    "    \n",
    "    # Rolling statistics\n",
    "    for window in [7, 14, 30]:\n",
    "        product_df[f'rolling_mean_{window}'] = product_df['demand'].rolling(window=window).mean()\n",
    "        product_df[f'rolling_std_{window}'] = product_df['demand'].rolling(window=window).std()\n",
    "    \n",
    "    # Date features\n",
    "    product_df['year'] = product_df['date'].dt.year\n",
    "    product_df['day_of_year'] = product_df['date'].dt.dayofyear\n",
    "    \n",
    "    # Drop NaN values\n",
    "    product_df = product_df.dropna()\n",
    "    \n",
    "    return product_df\n",
    "\n",
    "# Try it on Product_A\n",
    "product_df = create_features(df, 'Product_A')\n",
    "print(f\"Features created! Shape: {product_df.shape}\")\n",
    "print(f\"\\nFeature columns:\")\n",
    "print(product_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 5: Train Forecasting Models\n",
    "\n",
    "**Try This:** Change the product name below to analyze different products!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a product to analyze\n",
    "PRODUCT = 'Product_A'  # üëà CHANGE THIS TO TRY DIFFERENT PRODUCTS\n",
    "\n",
    "# Prepare data\n",
    "product_df = create_features(df, PRODUCT)\n",
    "feature_cols = [col for col in product_df.columns \n",
    "               if col not in ['date', 'product', 'demand', 'price']]\n",
    "\n",
    "X = product_df[feature_cols]\n",
    "y = product_df['demand']\n",
    "\n",
    "# Train-test split (80-20)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "dates_test = product_df['date'].iloc[split_idx:].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\n‚úÖ Data prepared for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'Linear Regression': LinearRegression()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'predictions': y_pred,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "    \n",
    "    print(f\"  MAE: {mae:.2f} | RMSE: {rmse:.2f} | R¬≤: {r2:.4f} | MAPE: {mape:.2f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ All models trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 6: Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'MAE': [results[m]['MAE'] for m in results.keys()],\n",
    "    'RMSE': [results[m]['RMSE'] for m in results.keys()],\n",
    "    'R¬≤': [results[m]['R2'] for m in results.keys()],\n",
    "    'MAPE': [results[m]['MAPE'] for m in results.keys()]\n",
    "})\n",
    "\n",
    "print(\"\\nüèÜ Model Performance Comparison:\")\n",
    "print(comparison_df.sort_values('MAPE'))\n",
    "\n",
    "# Best model\n",
    "best_model = comparison_df.loc[comparison_df['MAPE'].idxmin(), 'Model']\n",
    "print(f\"\\n‚≠ê Best Model: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# MAPE comparison\n",
    "axes[0].bar(comparison_df['Model'], comparison_df['MAPE'], color=['purple', 'teal', 'gold'])\n",
    "axes[0].set_ylabel('MAPE (%)')\n",
    "axes[0].set_title('Model Accuracy Comparison (Lower is Better)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# R¬≤ comparison\n",
    "axes[1].bar(comparison_df['Model'], comparison_df['R¬≤'], color=['purple', 'teal', 'gold'])\n",
    "axes[1].set_ylabel('R¬≤ Score')\n",
    "axes[1].set_title('Model Fit Comparison (Higher is Better)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Step 7: Visualize Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted for best model\n",
    "best_predictions = results[best_model]['predictions']\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(dates_test, y_test.values, label='Actual Demand', \n",
    "         linewidth=2, marker='o', markersize=4, alpha=0.7)\n",
    "plt.plot(dates_test, best_predictions, label=f'{best_model} Forecast', \n",
    "         linewidth=2, marker='s', markersize=4, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Demand')\n",
    "plt.title(f'{PRODUCT}: Actual vs Predicted Demand ({best_model})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 - results[best_model]['MAPE']\n",
    "print(f\"\\n‚úÖ Forecast Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 8: Inventory Optimization\n",
    "\n",
    "Calculate optimal inventory levels based on forecasts.\n",
    "\n",
    "**Try This:** Adjust the service level below (0.90 = 90%, 0.95 = 95%, 0.99 = 99%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "LEAD_TIME = 7  # days üëà CHANGE THIS\n",
    "SERVICE_LEVEL = 0.95  # 95% üëà CHANGE THIS\n",
    "\n",
    "# Calculate forecast error\n",
    "errors = y_test.values - best_predictions\n",
    "error_std = np.std(errors)\n",
    "\n",
    "# Average demand during lead time\n",
    "avg_demand_lead_time = np.mean(best_predictions) * LEAD_TIME\n",
    "\n",
    "# Safety stock\n",
    "z_score = stats.norm.ppf(SERVICE_LEVEL)\n",
    "safety_stock = z_score * error_std * np.sqrt(LEAD_TIME)\n",
    "\n",
    "# Reorder point\n",
    "reorder_point = avg_demand_lead_time + safety_stock\n",
    "\n",
    "# Economic Order Quantity\n",
    "annual_demand = np.sum(best_predictions) * (365 / len(best_predictions))\n",
    "holding_cost = 2  # $ per unit per year\n",
    "order_cost = 50  # $ per order\n",
    "eoq = np.sqrt((2 * annual_demand * order_cost) / holding_cost)\n",
    "\n",
    "print(\"\\nüì¶ INVENTORY OPTIMIZATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Average Daily Demand: {np.mean(best_predictions):.0f} units\")\n",
    "print(f\"Safety Stock: {safety_stock:.0f} units\")\n",
    "print(f\"Reorder Point: {reorder_point:.0f} units\")\n",
    "print(f\"Economic Order Quantity: {eoq:.0f} units\")\n",
    "print(f\"Service Level: {SERVICE_LEVEL*100:.0f}%\")\n",
    "print(f\"Stockout Risk: {(1-SERVICE_LEVEL)*100:.1f}%\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize inventory policy\n",
    "metrics = ['Avg Daily\\nDemand', 'Safety\\nStock', 'Reorder\\nPoint', 'EOQ']\n",
    "values = [np.mean(best_predictions), safety_stock, reorder_point, eoq]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(metrics, values, color=['#3498db', '#e74c3c', '#f39c12', '#2ecc71'], \n",
    "               edgecolor='black', linewidth=2)\n",
    "plt.ylabel('Units')\n",
    "plt.title(f'Inventory Policy for {PRODUCT}')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.0f}', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Step 9: Business Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüéØ ACTIONABLE RECOMMENDATIONS FOR {PRODUCT}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n1. FORECASTING:\")\n",
    "print(f\"   ‚Ä¢ Use {best_model} for demand prediction\")\n",
    "print(f\"   ‚Ä¢ Expected forecast accuracy: {100-results[best_model]['MAPE']:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Update forecasts weekly for best results\")\n",
    "\n",
    "print(f\"\\n2. INVENTORY POLICY:\")\n",
    "print(f\"   ‚Ä¢ Maintain {safety_stock:.0f} units as safety stock\")\n",
    "print(f\"   ‚Ä¢ Place order when inventory reaches {reorder_point:.0f} units\")\n",
    "print(f\"   ‚Ä¢ Order {eoq:.0f} units each time\")\n",
    "\n",
    "print(f\"\\n3. EXPECTED OUTCOMES:\")\n",
    "print(f\"   ‚Ä¢ {SERVICE_LEVEL*100:.0f}% order fulfillment rate\")\n",
    "print(f\"   ‚Ä¢ Only {(1-SERVICE_LEVEL)*100:.1f}% stockout risk\")\n",
    "print(f\"   ‚Ä¢ Optimized inventory holding costs\")\n",
    "\n",
    "print(f\"\\n4. COST IMPLICATIONS:\")\n",
    "holding_cost_total = safety_stock * holding_cost\n",
    "print(f\"   ‚Ä¢ Annual safety stock holding cost: ${holding_cost_total:.2f}\")\n",
    "print(f\"   ‚Ä¢ Orders per year: {annual_demand/eoq:.0f}\")\n",
    "print(f\"   ‚Ä¢ Annual ordering cost: ${(annual_demand/eoq)*order_cost:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Learning Exercises\n",
    "\n",
    "Try these experiments:\n",
    "\n",
    "### Exercise 1: Compare All Products\n",
    "Change `PRODUCT` variable and run analysis for each product. Which has:\n",
    "- Best forecast accuracy?\n",
    "- Highest safety stock requirement?\n",
    "- Most stable demand?\n",
    "\n",
    "### Exercise 2: Service Level Impact\n",
    "Try different service levels (0.90, 0.95, 0.99):\n",
    "- How does safety stock change?\n",
    "- What's the cost vs. risk tradeoff?\n",
    "\n",
    "### Exercise 3: Lead Time Sensitivity\n",
    "Change `LEAD_TIME` (3, 7, 14 days):\n",
    "- How does it affect reorder point?\n",
    "- Impact on safety stock?\n",
    "\n",
    "### Exercise 4: Feature Importance\n",
    "Which features matter most for prediction?\n",
    "```python\n",
    "# For Random Forest\n",
    "rf_model = models['Random Forest']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feature_importance)\n",
    "```\n",
    "\n",
    "### Exercise 5: Seasonal Analysis\n",
    "Plot monthly demand patterns:\n",
    "```python\n",
    "monthly_avg = df[df['product']==PRODUCT].groupby('month')['demand'].mean()\n",
    "monthly_avg.plot(kind='bar')\n",
    "plt.title('Average Demand by Month')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "To take this project further:\n",
    "\n",
    "1. **Real Data**: Try with your own sales data\n",
    "2. **More Models**: Add XGBoost, LSTM, Prophet\n",
    "3. **Dashboard**: Build with Streamlit or Dash\n",
    "4. **Automation**: Schedule daily forecasts\n",
    "5. **Multi-location**: Optimize across warehouses\n",
    "6. **Price Optimization**: Link pricing to demand\n",
    "7. **API**: Create REST API for predictions\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Learning! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
